name: Auto Update SEO Assets

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 0 * * *' 
  workflow_dispatch: 

jobs:
  seo:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Generate SEO Files
        shell: node {0}
        run: |
          const fs = require('fs');
          const path = require('path');

          const VERSION_DATE = new Date().toISOString().split('T')[0];
          const BASE_URL = 'https://hassanbiswas.github.io';
          
          // --- SITEMAP LOGIC ---
          const CONFIG = {
            '/': { priority: 1.0, changefreq: 'weekly' },
            '/about/': { priority: 0.8, changefreq: 'monthly' },
            '/services/': { priority: 0.8, changefreq: 'monthly' },
            '/contact/': { priority: 0.7, changefreq: 'monthly' }
          };

          const EXCLUSIONS = {
            folders: ['node_modules', '.git', 'dist'],
            files: ['404.html', 'test.html', 'draft.html']
          };

          const getHtmlFiles = (dir, fileList = []) => {
            const files = fs.readdirSync(dir);
            files.forEach(file => {
              const filePath = path.join(dir, file);
              const isDirectory = fs.statSync(filePath).isDirectory();
              if (isDirectory && EXCLUSIONS.folders.includes(file)) return;
              if (!isDirectory && EXCLUSIONS.files.includes(file)) return;

              if (isDirectory) {
                getHtmlFiles(filePath, fileList);
              } else if (file.endsWith('.html')) {
                let urlPath = filePath.replace(process.cwd(), '').replace(/\\/g, '/').replace(/index\.html$/, '');
                if (!urlPath.startsWith('/')) urlPath = '/' + urlPath;
                if (!urlPath.endsWith('/')) urlPath = urlPath + '/';
                fileList.push(urlPath);
              }
            });
            return [...new Set(fileList)];
          };

          const allPages = getHtmlFiles(process.cwd());
          const sitemapEntries = allPages.map(page => {
            const settings = CONFIG[page] || { priority: 0.5, changefreq: 'monthly' };
            return `  <url>\n    <loc>${BASE_URL}${page}</loc>\n    <lastmod>${VERSION_DATE}</lastmod>\n    <changefreq>${settings.changefreq}</changefreq>\n    <priority>${settings.priority.toFixed(1)}</priority>\n  </url>`;
          }).join('\n');

          const sitemap = `<?xml version="1.0" encoding="UTF-8"?>\n<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n${sitemapEntries}\n</urlset>`;
          fs.writeFileSync('sitemap.xml', sitemap);

          // --- ROBOTS.TXT LOGIC ---
          const robots = `# User-agent: * applies to all search engine bots
          User-agent: *
          Allow: /
          Disallow: /private/
          Disallow: /drafts/
          Disallow: /node_modules/
          Sitemap: ${BASE_URL}/sitemap.xml

          # End of file
          # Last updated: ${VERSION_DATE}`.replace(/^\s+/gm, ''); // Cleans up indentation

          fs.writeFileSync('robots.txt', robots);
          console.log(\`SEO Assets Sync complete: \${allPages.length} URLs processed.\`);

      - name: Commit and Push Changes
        run: |
          git config --global user.name "Hassan Biswas (Automation)"
          git config --global user.email "hassanbiswas.github.io@gmail.com"
          
          git add sitemap.xml robots.txt
          
          VERSION=$(date +'%d')
          if ! git diff --cached --quiet; then
            git commit -m "chore: SEO sync v$VERSION update $(date +'%Y-%m-%d') [skip ci]"
            git push
          else
            echo "No changes detected in SEO files."
          fi

      - name: Ping Search Engines
        run: |
          curl "https://www.google.com/ping?sitemap=https://hassanbiswas.github.io/sitemap.xml" || echo "Google ping failed"
          curl "https://www.bing.com/ping?sitemap=https://hassanbiswas.github.io/sitemap.xml" || echo "Bing ping failed"
          
